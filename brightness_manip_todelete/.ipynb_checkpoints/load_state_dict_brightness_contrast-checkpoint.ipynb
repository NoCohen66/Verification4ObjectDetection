{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abf70cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "import torch \n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "from auto_LiRPA import BoundedModule, BoundedTensor, PerturbationLpNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1b20856-8b0f-4f86-9dc1-f509180a0c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ncohmpli/Documents/Professionnel/Technical/Verification/Lirpa for IoU/manip/pipeline\n"
     ]
    }
   ],
   "source": [
    "cd /Users/ncohmpli/Documents/Professionnel/Technical/Verification/Lirpa for IoU/manip/pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c52b035c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork_BrightnessContrast(nn.Module):\n",
    "    '''\n",
    "    New model that takes as input a brightness or constrat value and apply it to a specific image\n",
    "    using the linear_perturbation layer\n",
    "    (aka the weight and biases of the linear_perturbation layer are set to specific values to encode\n",
    "    brightness or contrast for a specific image)\n",
    "    '''\n",
    "    def __init__(self, classif=True):\n",
    "        super(NeuralNetwork_BrightnessContrast, self).__init__()\n",
    "        self.classif=classif\n",
    "        seed = 0\n",
    "        torch.manual_seed(seed)\n",
    "        padding = 1\n",
    "        self.linear_perturbation = nn.Linear(1,90*90)\n",
    "        self.conv0 = nn.Conv2d(1, 16, 3, padding= padding) # 3x3 filters w/ same padding\n",
    "        self.pool0 = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv1 = nn.Conv2d(16, 16, 3, padding= padding) # 3x3 filters w/ same padding\n",
    "        self.pool1 = nn.MaxPool2d(2, stride=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack= nn.Linear(7744,256)\n",
    "        if self.classif:\n",
    "            self.linear = nn.Linear(256, 10)\n",
    "        else:\n",
    "            self.linear_all = nn.Linear(256, 4) \n",
    "\n",
    "    \n",
    "    def forward(self, alpha):\n",
    "        layer = self.linear_perturbation(alpha)\n",
    "        layer = layer.view((-1, 1, 90, 90))\n",
    "        layer = self.conv0(layer)\n",
    "        layer = F.relu(self.pool0(layer))\n",
    "        layer = self.conv1(layer)\n",
    "        layer = F.relu(self.pool1(layer))\n",
    "        layer = self.flatten(layer)\n",
    "        layer = self.linear_relu_stack(layer)\n",
    "        layer = F.relu(layer)\n",
    "        if self.classif:\n",
    "            logits = self.linear(layer)\n",
    "        else:\n",
    "            logits = self.linear_all(layer)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27fd5018-4924-4ad7-a278-6340f360b863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1079, -0.0068, -0.0729, -0.0156]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_test = NeuralNetwork_BrightnessContrast(classif=False)\n",
    "model_test(torch.Tensor([0.001]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bac34c",
   "metadata": {},
   "source": [
    "## Digit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "592eca4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_digit = NeuralNetwork_BrightnessContrast(classif=True)\n",
    "\n",
    "filename = 'toy_model_classif'\n",
    "model_torch_load  = torch.jit.load(f'{filename}.pt')\n",
    "digit_config = model_torch_load.state_dict()\n",
    "digit_config['linear_perturbation.weight']=torch.Tensor(np.zeros((90*90, 1), dtype='float32'))\n",
    "digit_config['linear_perturbation.bias']=torch.Tensor(np.zeros((90*90,), dtype='float32'))\n",
    "model_digit.load_state_dict(digit_config)\n",
    "#model_torch_load.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c035acf4",
   "metadata": {},
   "source": [
    "## Corner Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "804e9c51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_corners = NeuralNetwork_BrightnessContrast(classif=False)\n",
    "\n",
    "filename = 'toy_model_corners'\n",
    "model_torch_load  = torch.jit.load(f'{filename}.pt')\n",
    "corner_config = model_torch_load.state_dict()\n",
    "# we create values for the linear_perturbation parameters that will me set for brightness and contrast afterwards\n",
    "corner_config['linear_perturbation.weight']=torch.Tensor(np.zeros((90*90, 1), dtype='float32'))\n",
    "corner_config['linear_perturbation.bias']=torch.Tensor(np.zeros((90*90,), dtype='float32'))\n",
    "model_corners.load_state_dict(corner_config)\n",
    "#model_torch_load.state_dict()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb48bc0",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6ce420b-3959-475e-a26b-67111533a009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ncohmpli/Documents/Professionnel/Technical/Verification/Lirpa for IoU/manip/pipeline/utils\n"
     ]
    }
   ],
   "source": [
    "cd utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b77dd846-6e4d-4906-83a5-8bd5b0bf0584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m__pycache__\u001b[m\u001b[m/   custom_op.py   \u001b[34mdata\u001b[m\u001b[m/          model_func.py  train.csv\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a434e0c-37e7-4e20-94fd-2d040367889d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_func import *\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d635bbb7-2890-4802-af63-69e972abe4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "dict_df_10 = {}\n",
    "for label in np.unique(list(train_df[\"label\"])): \n",
    "    print(label)\n",
    "    dict_df_10[label] = train_df[train_df[\"label\"] == label].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e92b4ad-8556-4ce9-b972-8e4cd5d55a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_100 = pd.concat(dict_df_10.values())\n",
    "trainingData = CustomMnistDataset_OL(train_df_100)\n",
    "train_dataloader = DataLoader(trainingData, batch_size=1, shuffle=False)\n",
    "iterator = iter(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b31847ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(train_dataloader))\n",
    "X_0, _ = data\n",
    "data = next(iter(train_dataloader))\n",
    "X_1, _ = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a396272e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create brightness values\n",
    "brightness_range = np.asarray(np.linspace(0, 0.5, 100), 'float32')\n",
    "brightness_min = brightness_range[:-1]\n",
    "brightness_max = brightness_range[1:]\n",
    "\n",
    "brightness_center = (brightness_min+brightness_max)/2.\n",
    "eps_brightness = ((brightness_max-brightness_min)/2.).max()\n",
    "\n",
    "X_brightness = torch.Tensor(brightness_center[:,None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "602224db-0882-4383-ae71-a270e21ae97d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([99, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_brightness.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6479127c",
   "metadata": {},
   "source": [
    "## Brightness\n",
    "\n",
    "brightness(x; alpha)= x+ alpha\n",
    "\n",
    "thus for linear_perturbation\n",
    "\n",
    "linear_perturbation.weight = [1..1]\n",
    "\n",
    "linear_perturbation.weight = x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea45d9ef",
   "metadata": {},
   "source": [
    "## Contrast\n",
    "\n",
    "contrast(x; alpha)= x*alpha\n",
    "\n",
    "thus for linear_perturbation\n",
    "\n",
    "linear_perturbation.weight = x\n",
    "\n",
    "linear_perturbation.bias = [0..0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe57d32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_brightness(model, image):\n",
    "    # create a pytorch model for a specific flatten image\n",
    "    # once a model has been set for one images, you can call it for any brightness value\n",
    "    image_flatten = image.view((90*90,))\n",
    "    brightness_config = model.state_dict()\n",
    "    brightness_config['linear_perturbation.bias']=image_flatten\n",
    "    brightness_config['linear_perturbation.weight']=torch.Tensor(np.ones((90*90,1), dtype='float32'))\n",
    "    model.load_state_dict(brightness_config)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6948ad8f",
   "metadata": {},
   "source": [
    "## AutoLirpa on brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06774316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "be careful Noémie is doing shit on auto lirpa [BoundInput(name=\"/0\"), BoundParams(name=\"/1\"), BoundParams(name=\"/2\"), BoundParams(name=\"/3\"), BoundParams(name=\"/4\"), BoundParams(name=\"/5\"), BoundParams(name=\"/6\"), BoundParams(name=\"/7\"), BoundParams(name=\"/8\"), BoundParams(name=\"/9\"), BoundParams(name=\"/10\")] ['/0', '/1', '/2', '/3', '/4', '/5', '/6', '/7', '/8', '/9', '/10']\n",
      "<BoundedTensor: BoundedTensor([[0.0025],\n",
      "               [0.0076],\n",
      "               [0.0126],\n",
      "               [0.0177],\n",
      "               [0.0227],\n",
      "               [0.0278],\n",
      "               [0.0328],\n",
      "               [0.0379],\n",
      "               [0.0429],\n",
      "               [0.0480],\n",
      "               [0.0530],\n",
      "               [0.0581],\n",
      "               [0.0631],\n",
      "               [0.0682],\n",
      "               [0.0732],\n",
      "               [0.0783],\n",
      "               [0.0833],\n",
      "               [0.0884],\n",
      "               [0.0934],\n",
      "               [0.0985],\n",
      "               [0.1035],\n",
      "               [0.1086],\n",
      "               [0.1136],\n",
      "               [0.1187],\n",
      "               [0.1237],\n",
      "               [0.1288],\n",
      "               [0.1338],\n",
      "               [0.1389],\n",
      "               [0.1439],\n",
      "               [0.1490],\n",
      "               [0.1540],\n",
      "               [0.1591],\n",
      "               [0.1641],\n",
      "               [0.1692],\n",
      "               [0.1742],\n",
      "               [0.1793],\n",
      "               [0.1843],\n",
      "               [0.1894],\n",
      "               [0.1944],\n",
      "               [0.1995],\n",
      "               [0.2045],\n",
      "               [0.2096],\n",
      "               [0.2146],\n",
      "               [0.2197],\n",
      "               [0.2247],\n",
      "               [0.2298],\n",
      "               [0.2348],\n",
      "               [0.2399],\n",
      "               [0.2449],\n",
      "               [0.2500],\n",
      "               [0.2551],\n",
      "               [0.2601],\n",
      "               [0.2652],\n",
      "               [0.2702],\n",
      "               [0.2753],\n",
      "               [0.2803],\n",
      "               [0.2854],\n",
      "               [0.2904],\n",
      "               [0.2955],\n",
      "               [0.3005],\n",
      "               [0.3056],\n",
      "               [0.3106],\n",
      "               [0.3157],\n",
      "               [0.3207],\n",
      "               [0.3258],\n",
      "               [0.3308],\n",
      "               [0.3359],\n",
      "               [0.3409],\n",
      "               [0.3460],\n",
      "               [0.3510],\n",
      "               [0.3561],\n",
      "               [0.3611],\n",
      "               [0.3662],\n",
      "               [0.3712],\n",
      "               [0.3763],\n",
      "               [0.3813],\n",
      "               [0.3864],\n",
      "               [0.3914],\n",
      "               [0.3965],\n",
      "               [0.4015],\n",
      "               [0.4066],\n",
      "               [0.4116],\n",
      "               [0.4167],\n",
      "               [0.4217],\n",
      "               [0.4268],\n",
      "               [0.4318],\n",
      "               [0.4369],\n",
      "               [0.4419],\n",
      "               [0.4470],\n",
      "               [0.4520],\n",
      "               [0.4571],\n",
      "               [0.4621],\n",
      "               [0.4672],\n",
      "               [0.4722],\n",
      "               [0.4773],\n",
      "               [0.4823],\n",
      "               [0.4874],\n",
      "               [0.4924],\n",
      "               [0.4975]]), PerturbationLpNorm(norm=inf, eps=0.001)>\n",
      "BoundInput(name=\"/0\")\n",
      "be careful added by Noemie\n",
      "be careful added by Noemie\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def expe_brightness(X_0, model_digit): \n",
    "    set_brightness(model_digit, X_0)\n",
    "    model_lirpa_digit = BoundedModule(model_digit, X_brightness)\n",
    "    ptb_brightness = PerturbationLpNorm(norm=np.inf, eps=0.001)\n",
    "    input_lirpa_brightness = BoundedTensor(X_brightness, ptb_brightness)\n",
    "    \n",
    "    lb_brightness, ub_brightness = model_lirpa_digit.compute_bounds(x=(input_lirpa_brightness,),\n",
    "                                                        IBP=True, method='crown')\n",
    "    return(lb_brightness, ub_brightness)\n",
    "\n",
    "lb_test,  ub_test = expe_brightness(X_0, model_corners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cc8e0a-a46b-401c-9b9f-54d81dbaf883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin to work with image 0\n",
      "be careful Noémie is doing shit on auto lirpa [BoundInput(name=\"/0\"), BoundParams(name=\"/1\"), BoundParams(name=\"/2\"), BoundParams(name=\"/3\"), BoundParams(name=\"/4\"), BoundParams(name=\"/5\"), BoundParams(name=\"/6\"), BoundParams(name=\"/7\"), BoundParams(name=\"/8\"), BoundParams(name=\"/9\"), BoundParams(name=\"/10\")] ['/0', '/1', '/2', '/3', '/4', '/5', '/6', '/7', '/8', '/9', '/10']\n",
      "<BoundedTensor: BoundedTensor([[0.0025],\n",
      "               [0.0076],\n",
      "               [0.0126],\n",
      "               [0.0177],\n",
      "               [0.0227],\n",
      "               [0.0278],\n",
      "               [0.0328],\n",
      "               [0.0379],\n",
      "               [0.0429],\n",
      "               [0.0480],\n",
      "               [0.0530],\n",
      "               [0.0581],\n",
      "               [0.0631],\n",
      "               [0.0682],\n",
      "               [0.0732],\n",
      "               [0.0783],\n",
      "               [0.0833],\n",
      "               [0.0884],\n",
      "               [0.0934],\n",
      "               [0.0985],\n",
      "               [0.1035],\n",
      "               [0.1086],\n",
      "               [0.1136],\n",
      "               [0.1187],\n",
      "               [0.1237],\n",
      "               [0.1288],\n",
      "               [0.1338],\n",
      "               [0.1389],\n",
      "               [0.1439],\n",
      "               [0.1490],\n",
      "               [0.1540],\n",
      "               [0.1591],\n",
      "               [0.1641],\n",
      "               [0.1692],\n",
      "               [0.1742],\n",
      "               [0.1793],\n",
      "               [0.1843],\n",
      "               [0.1894],\n",
      "               [0.1944],\n",
      "               [0.1995],\n",
      "               [0.2045],\n",
      "               [0.2096],\n",
      "               [0.2146],\n",
      "               [0.2197],\n",
      "               [0.2247],\n",
      "               [0.2298],\n",
      "               [0.2348],\n",
      "               [0.2399],\n",
      "               [0.2449],\n",
      "               [0.2500],\n",
      "               [0.2551],\n",
      "               [0.2601],\n",
      "               [0.2652],\n",
      "               [0.2702],\n",
      "               [0.2753],\n",
      "               [0.2803],\n",
      "               [0.2854],\n",
      "               [0.2904],\n",
      "               [0.2955],\n",
      "               [0.3005],\n",
      "               [0.3056],\n",
      "               [0.3106],\n",
      "               [0.3157],\n",
      "               [0.3207],\n",
      "               [0.3258],\n",
      "               [0.3308],\n",
      "               [0.3359],\n",
      "               [0.3409],\n",
      "               [0.3460],\n",
      "               [0.3510],\n",
      "               [0.3561],\n",
      "               [0.3611],\n",
      "               [0.3662],\n",
      "               [0.3712],\n",
      "               [0.3763],\n",
      "               [0.3813],\n",
      "               [0.3864],\n",
      "               [0.3914],\n",
      "               [0.3965],\n",
      "               [0.4015],\n",
      "               [0.4066],\n",
      "               [0.4116],\n",
      "               [0.4167],\n",
      "               [0.4217],\n",
      "               [0.4268],\n",
      "               [0.4318],\n",
      "               [0.4369],\n",
      "               [0.4419],\n",
      "               [0.4470],\n",
      "               [0.4520],\n",
      "               [0.4571],\n",
      "               [0.4621],\n",
      "               [0.4672],\n",
      "               [0.4722],\n",
      "               [0.4773],\n",
      "               [0.4823],\n",
      "               [0.4874],\n",
      "               [0.4924],\n",
      "               [0.4975]]), PerturbationLpNorm(norm=inf, eps=0.001)>\n",
      "BoundInput(name=\"/0\")\n",
      "be careful added by Noemie\n",
      "be careful added by Noemie\n",
      "Begin to work with image 1\n",
      "be careful Noémie is doing shit on auto lirpa [BoundInput(name=\"/0\"), BoundParams(name=\"/1\"), BoundParams(name=\"/2\"), BoundParams(name=\"/3\"), BoundParams(name=\"/4\"), BoundParams(name=\"/5\"), BoundParams(name=\"/6\"), BoundParams(name=\"/7\"), BoundParams(name=\"/8\"), BoundParams(name=\"/9\"), BoundParams(name=\"/10\")] ['/0', '/1', '/2', '/3', '/4', '/5', '/6', '/7', '/8', '/9', '/10']\n",
      "<BoundedTensor: BoundedTensor([[0.0025],\n",
      "               [0.0076],\n",
      "               [0.0126],\n",
      "               [0.0177],\n",
      "               [0.0227],\n",
      "               [0.0278],\n",
      "               [0.0328],\n",
      "               [0.0379],\n",
      "               [0.0429],\n",
      "               [0.0480],\n",
      "               [0.0530],\n",
      "               [0.0581],\n",
      "               [0.0631],\n",
      "               [0.0682],\n",
      "               [0.0732],\n",
      "               [0.0783],\n",
      "               [0.0833],\n",
      "               [0.0884],\n",
      "               [0.0934],\n",
      "               [0.0985],\n",
      "               [0.1035],\n",
      "               [0.1086],\n",
      "               [0.1136],\n",
      "               [0.1187],\n",
      "               [0.1237],\n",
      "               [0.1288],\n",
      "               [0.1338],\n",
      "               [0.1389],\n",
      "               [0.1439],\n",
      "               [0.1490],\n",
      "               [0.1540],\n",
      "               [0.1591],\n",
      "               [0.1641],\n",
      "               [0.1692],\n",
      "               [0.1742],\n",
      "               [0.1793],\n",
      "               [0.1843],\n",
      "               [0.1894],\n",
      "               [0.1944],\n",
      "               [0.1995],\n",
      "               [0.2045],\n",
      "               [0.2096],\n",
      "               [0.2146],\n",
      "               [0.2197],\n",
      "               [0.2247],\n",
      "               [0.2298],\n",
      "               [0.2348],\n",
      "               [0.2399],\n",
      "               [0.2449],\n",
      "               [0.2500],\n",
      "               [0.2551],\n",
      "               [0.2601],\n",
      "               [0.2652],\n",
      "               [0.2702],\n",
      "               [0.2753],\n",
      "               [0.2803],\n",
      "               [0.2854],\n",
      "               [0.2904],\n",
      "               [0.2955],\n",
      "               [0.3005],\n",
      "               [0.3056],\n",
      "               [0.3106],\n",
      "               [0.3157],\n",
      "               [0.3207],\n",
      "               [0.3258],\n",
      "               [0.3308],\n",
      "               [0.3359],\n",
      "               [0.3409],\n",
      "               [0.3460],\n",
      "               [0.3510],\n",
      "               [0.3561],\n",
      "               [0.3611],\n",
      "               [0.3662],\n",
      "               [0.3712],\n",
      "               [0.3763],\n",
      "               [0.3813],\n",
      "               [0.3864],\n",
      "               [0.3914],\n",
      "               [0.3965],\n",
      "               [0.4015],\n",
      "               [0.4066],\n",
      "               [0.4116],\n",
      "               [0.4167],\n",
      "               [0.4217],\n",
      "               [0.4268],\n",
      "               [0.4318],\n",
      "               [0.4369],\n",
      "               [0.4419],\n",
      "               [0.4470],\n",
      "               [0.4520],\n",
      "               [0.4571],\n",
      "               [0.4621],\n",
      "               [0.4672],\n",
      "               [0.4722],\n",
      "               [0.4773],\n",
      "               [0.4823],\n",
      "               [0.4874],\n",
      "               [0.4924],\n",
      "               [0.4975]]), PerturbationLpNorm(norm=inf, eps=0.001)>\n",
      "BoundInput(name=\"/0\")\n",
      "be careful added by Noemie\n",
      "be careful added by Noemie\n"
     ]
    }
   ],
   "source": [
    "dico = {}\n",
    "for image_id in range(len(train_df_100)):\n",
    "    list_info = []\n",
    "    print(f\"Begin to work with image {image_id}\")\n",
    "    data = next(iterator)\n",
    "    X, y = data\n",
    "    lb, ub = expe_brightness(X, model_digit)\n",
    "    dico[image_id] = lb, ub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83640dbd-8373-4a80-86b9-9cbbc6466c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccae739-978a-41c9-b0d4-853346235cc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
